{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.3\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NYCTaxiAnalysis\").getOrCreate()\n",
    "df_taxi = spark.read.option(\"header\", \"true\").csv(\"input/Sample NYC Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- vendor_id: string (nullable = true)\n",
      " |-- rate_code: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- pickup_longitude: string (nullable = true)\n",
      " |-- pickup_latitude: string (nullable = true)\n",
      " |-- dropoff_longitude: string (nullable = true)\n",
      " |-- dropoff_latitude: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
      "|           medallion|        hack_license|vendor_id|rate_code|store_and_fwd_flag|pickup_datetime|dropoff_datetime|passenger_count|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|\n",
      "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
      "|89D227B655E5C82AE...|BA96DE419E711691B...|      CMT|        1|                 N| 01-01-13 15:11|  01-01-13 15:18|              4|      -73.978165|      40.757977|       -73.989838|       40.751171|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N| 06-01-13 00:18|  06-01-13 00:22|              1|      -74.006683|      40.731781|       -73.994499|        40.75066|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N| 05-01-13 18:49|  05-01-13 18:54|              1|      -74.004707|       40.73777|       -74.009834|       40.726002|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|        1|                 N| 07-01-13 23:54|  07-01-13 23:58|              2|      -73.974602|      40.759945|       -73.984734|       40.759388|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|        1|                 N| 07-01-13 23:25|  07-01-13 23:34|              1|       -73.97625|      40.748528|       -74.002586|       40.747868|\n",
      "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_taxi.printSchema()\n",
    "df_taxi.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create duration column\n",
    "from pyspark.sql.functions import unix_timestamp, col\n",
    "\n",
    "df_taxi = df_taxi.withColumn(\n",
    "    \"pickup_ts\",\n",
    "    unix_timestamp(col(\"pickup_datetime\"), \"dd-MM-yy HH:mm\")\n",
    ")\n",
    "\n",
    "df_taxi = df_taxi.withColumn(\n",
    "    \"dropoff_ts\",\n",
    "    unix_timestamp(col(\"dropoff_datetime\"), \"dd-MM-yy HH:mm\")\n",
    ")\n",
    "\n",
    "df_taxi = df_taxi.withColumn(\n",
    "    \"duration_sec\",\n",
    "    col(\"dropoff_ts\") - col(\"pickup_ts\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      duration_sec|\n",
      "+-------+------------------+\n",
      "|  count|             99999|\n",
      "|    min|                 0|\n",
      "|    max|              9180|\n",
      "|   mean| 650.6807068070681|\n",
      "| stddev|469.78651920883175|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_taxi.select(\"duration_sec\").summary(\"count\", \"min\", \"max\", \"mean\", \"stddev\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rides with duration at least 0 second duration and at most 2.5h duration\n",
    "df_taxi = df_taxi.filter((col(\"duration_sec\") >= 0) & (col(\"duration_sec\") <= 2.5*60*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      duration_sec|\n",
      "+-------+------------------+\n",
      "|  count|             99998|\n",
      "|    min|                 0|\n",
      "|    max|              8820|\n",
      "|   mean| 650.5954119082381|\n",
      "| stddev|469.01392166279226|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_taxi.select(\"duration_sec\").summary(\"count\", \"min\", \"max\", \"mean\", \"stddev\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|   passenger_count|\n",
      "+-------+------------------+\n",
      "|  count|             99998|\n",
      "|    min|                 0|\n",
      "|    max|                 6|\n",
      "|   mean|2.1629832596651934|\n",
      "| stddev|1.7398872965148953|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if there is passenger_count == 0\n",
    "df_taxi.select(\"passenger_count\").summary(\"count\", \"min\", \"max\", \"mean\", \"stddev\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does passenger_count == 0 mean idle time? Ignore for now, since not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can remove all unnecessary columns\n",
    "df_taxi = df_taxi.drop(\n",
    "    col(\"vendor_id\"),\n",
    "    col(\"rate_code\"), \n",
    "    col(\"store_and_fwd_flag\"), \n",
    "    col(\"pickup_datetime\"),\n",
    "    col(\"dropoff_datetime\"),\n",
    "    col(\"passenger_count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- pickup_longitude: string (nullable = true)\n",
      " |-- pickup_latitude: string (nullable = true)\n",
      " |-- dropoff_longitude: string (nullable = true)\n",
      " |-- dropoff_latitude: string (nullable = true)\n",
      " |-- pickup_ts: long (nullable = true)\n",
      " |-- dropoff_ts: long (nullable = true)\n",
      " |-- duration_sec: long (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+----------------+---------------+-----------------+----------------+----------+----------+------------+\n",
      "|           medallion|        hack_license|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude| pickup_ts|dropoff_ts|duration_sec|\n",
      "+--------------------+--------------------+----------------+---------------+-----------------+----------------+----------+----------+------------+\n",
      "|89D227B655E5C82AE...|BA96DE419E711691B...|      -73.978165|      40.757977|       -73.989838|       40.751171|1357053060|1357053480|         420|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      -74.006683|      40.731781|       -73.994499|        40.75066|1357431480|1357431720|         240|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      -74.004707|       40.73777|       -74.009834|       40.726002|1357411740|1357412040|         300|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      -73.974602|      40.759945|       -73.984734|       40.759388|1357602840|1357603080|         240|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|       -73.97625|      40.748528|       -74.002586|       40.747868|1357601100|1357601640|         540|\n",
      "+--------------------+--------------------+----------------+---------------+-----------------+----------------+----------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_taxi.printSchema()\n",
    "df_taxi.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely\n",
      "  Using cached shapely-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.11/site-packages (from shapely) (1.26.4)\n",
      "Using cached shapely-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Installing collected packages: shapely\n",
      "Successfully installed shapely-2.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from shapely.geometry import shape\n",
    "\n",
    "with open(\"input/nyc-boroughs.geojson\", \"r\") as f:\n",
    "    geojson_data = json.load(f)\n",
    "\n",
    "# Extract features\n",
    "features = geojson_data[\"features\"]\n",
    "\n",
    "# Sort features by borough code and area (descending)\n",
    "def feature_sort_key(f):\n",
    "    borough_code = f[\"properties\"][\"boroughCode\"]\n",
    "    polygon_area = shape(f[\"geometry\"]).area\n",
    "    return (borough_code, polygon_area * -1)  # negative for descending on area\n",
    "\n",
    "features_sorted = sorted(features, key=feature_sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcast the GeoJSON\n",
    "bc_features = spark.sparkContext.broadcast(features_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a UDF to Map Coordinates → Borough\n",
    "from shapely.geometry import Point\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def get_borough(lon, lat, features):\n",
    "    if lon is None or lat is None:\n",
    "        return None\n",
    "    point = Point(float(lon), float(lat))\n",
    "    for f in features:\n",
    "        polygon = shape(f[\"geometry\"])\n",
    "        if polygon.contains(point):\n",
    "            return f[\"properties\"][\"borough\"]\n",
    "    return None\n",
    "\n",
    "def udf_get_borough(lon, lat):\n",
    "    return get_borough(lon, lat, bc_features.value)\n",
    "\n",
    "borough_udf = udf(udf_get_borough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the UDF\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_taxi = df_taxi.withColumn(\"pickup_borough\",\n",
    "    borough_udf(col(\"pickup_longitude\"), col(\"pickup_latitude\"))\n",
    ")\n",
    "\n",
    "df_taxi = df_taxi.withColumn(\"dropoff_borough\",\n",
    "    borough_udf(col(\"dropoff_longitude\"), col(\"dropoff_latitude\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove longitude latitude\n",
    "df_taxi = df_taxi.drop(\n",
    "    col(\"pickup_longitude\"),\n",
    "    col(\"pickup_latitude\"),\n",
    "    col(\"dropoff_longitude\"),\n",
    "    col(\"dropoff_latitude\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- pickup_ts: long (nullable = true)\n",
      " |-- dropoff_ts: long (nullable = true)\n",
      " |-- duration_sec: long (nullable = true)\n",
      " |-- pickup_borough: string (nullable = true)\n",
      " |-- dropoff_borough: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+----------+----------+------------+--------------+---------------+\n",
      "|           medallion|        hack_license| pickup_ts|dropoff_ts|duration_sec|pickup_borough|dropoff_borough|\n",
      "+--------------------+--------------------+----------+----------+------------+--------------+---------------+\n",
      "|89D227B655E5C82AE...|BA96DE419E711691B...|1357053060|1357053480|         420|     Manhattan|      Manhattan|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|1357431480|1357431720|         240|     Manhattan|      Manhattan|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|1357411740|1357412040|         300|     Manhattan|      Manhattan|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|1357602840|1357603080|         240|     Manhattan|      Manhattan|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|1357601100|1357601640|         540|     Manhattan|      Manhattan|\n",
      "+--------------------+--------------------+----------+----------+------------+--------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_taxi.printSchema()\n",
    "df_taxi.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99998"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# caching the DataFrame\n",
    "df_taxi.cache()\n",
    "df_taxi.count()  # trigger the cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partion and sort\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# For cab utilization, use medallion, for taxi driver productivity, use hack_license\n",
    "window_spec = Window.partitionBy(\"medallion\").orderBy(\"pickup_ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Idle Time\n",
    "# Compare the pickup time of the current trip to the dropoff time of the previous trip:\n",
    "df_taxi = df_taxi.withColumn(\n",
    "  \"prev_dropoff_ts\",\n",
    "  F.lag(\"dropoff_ts\").over(window_spec)\n",
    ")\n",
    "df_taxi = df_taxi.withColumn(\n",
    "  \"idle_time_sec\",\n",
    "  col(\"pickup_ts\") - col(\"prev_dropoff_ts\")\n",
    ")\n",
    "# Replace null with 0 for the first trip\n",
    "df_taxi = df_taxi.fillna({\"idle_time_sec\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore very large idle times (e.g., >4 hours) as new sessions. Maybe we do not need this.\n",
    "df_taxi = df_taxi.withColumn(\n",
    "  \"idle_time_sec\",\n",
    "  F.when(col(\"idle_time_sec\") <= 4*60*60, col(\"idle_time_sec\")).otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Required Queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilization (per Taxi/Driver)\n",
    "# “Fraction of time a taxi is occupied.”\n",
    "#Summation of driving time vs. total time (driving + idle)\n",
    "\n",
    "df_trip_time = df_taxi.groupBy(\"medallion\") \\\n",
    "    .agg(F.sum(\"duration_sec\").alias(\"sum_trip_time\"))\n",
    "\n",
    "df_idle_time = df_taxi.groupBy(\"medallion\") \\\n",
    "    .agg(F.sum(\"idle_time_sec\").alias(\"sum_idle_time\"))\n",
    "\n",
    "df_util = df_trip_time.join(df_idle_time, on=\"medallion\") \\\n",
    "    .withColumn(\n",
    "        \"utilization\",\n",
    "        F.col(\"sum_trip_time\") / (F.col(\"sum_trip_time\") + F.col(\"sum_idle_time\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|dropoff_borough|      avg_idle_sec|\n",
      "+---------------+------------------+\n",
      "|         Queens| 1194.029975020816|\n",
      "|           NULL|1215.2891396332864|\n",
      "|       Brooklyn|1170.3303509979353|\n",
      "|  Staten Island|            2736.0|\n",
      "|      Manhattan|1012.9720330039336|\n",
      "|          Bronx| 1278.841463414634|\n",
      "+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average Time to Next Fare (per Destination Borough)\n",
    "\n",
    "# \"lead\" so we can shift the idle time back one row\n",
    "df_taxi = df_taxi.withColumn(\n",
    "  \"idle_time_for_this_dropoff\",\n",
    "  F.lag(\"idle_time_sec\").over(window_spec)\n",
    ")\n",
    "# group by dropoff_borough\n",
    "df_avg_idle = df_taxi.groupBy(\"dropoff_borough\") \\\n",
    "    .agg(F.avg(\"idle_time_for_this_dropoff\").alias(\"avg_idle_sec\"))\n",
    "df_avg_idle.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|pickup_borough|count|\n",
      "+--------------+-----+\n",
      "|        Queens| 1396|\n",
      "|      Brooklyn| 1065|\n",
      "| Staten Island|    1|\n",
      "|     Manhattan|83560|\n",
      "|         Bronx|   51|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of Trips that Start and End in the Same Borough\n",
    "\n",
    "df_same = df_taxi.filter(col(\"pickup_borough\") == col(\"dropoff_borough\"))\n",
    "count_same = df_same.count()\n",
    "\n",
    "# broken down by borough\n",
    "df_same.groupBy(\"pickup_borough\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+-----+\n",
      "|pickup_borough|dropoff_borough|count|\n",
      "+--------------+---------------+-----+\n",
      "|      Brooklyn|      Manhattan|  774|\n",
      "|        Queens|          Bronx|  100|\n",
      "|      Brooklyn|         Queens|  115|\n",
      "|        Queens|  Staten Island|    2|\n",
      "|     Manhattan|  Staten Island|    9|\n",
      "|     Manhattan|       Brooklyn| 1923|\n",
      "|     Manhattan|         Queens| 3943|\n",
      "|     Manhattan|          Bronx|  244|\n",
      "|        Queens|      Manhattan| 3698|\n",
      "|         Bronx|      Manhattan|   25|\n",
      "|        Queens|       Brooklyn|  597|\n",
      "|         Bronx|         Queens|    2|\n",
      "| Staten Island|         Queens|    1|\n",
      "+--------------+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of Trips from One Borough to Another\n",
    "\n",
    "df_diff = df_taxi.filter(col(\"pickup_borough\") != col(\"dropoff_borough\"))\n",
    "count_diff = df_diff.count()\n",
    "\n",
    "# Per borough pair\n",
    "df_diff.groupBy(\"pickup_borough\", \"dropoff_borough\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util.coalesce(1).write.csv(\"output\", header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
